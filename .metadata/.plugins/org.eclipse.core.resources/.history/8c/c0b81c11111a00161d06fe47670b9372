#include "Histogramme.h"
#include <assert.h>

#include <iostream>

#include "Device.h"

#define N256 256;

using std::cout;
using std::endl;

/*----------------------------------------------------------------------*\
 |*			Declaration 					*|
 \*---------------------------------------------------------------------*/

/*--------------------------------------*\
 |*		Imported	 	*|
 \*-------------------------------------*/

extern __global__ void histogramme(uchar* ptrDevTabData, int nTabData, int* ptrDevHisto);

/*--------------------------------------*\
 |*		Public			*|
 \*-------------------------------------*/

/*--------------------------------------*\
 |*		Private			*|
 \*-------------------------------------*/

/*----------------------------------------------------------------------*\
 |*			Implementation 					*|
 \*---------------------------------------------------------------------*/

/*--------------------------------------*\
 |*		Constructeur			*|
 \*-------------------------------------*/

Histogramme::Histogramme()
    {
    this->nTabData = N256 * (N256+1) / 2;
    this->sizeOctetData = nTabData * sizeof(uchar); // octet
    this->sizeOctetHisto = N256 * sizeof(int); // octet
    this->tabData = new uchar[nTabData];
    this->ptrHisto = new int[N256];

    int s =0;
    for (int i = 0; i < nTabData; i++)
	{
	for(int j = 0; j< i; j++)
	    {
	    this->tabData[s] = i;
	    s++;
	    }
	}
    assert (s == nTabData);

    // MM
	{
	// MM (malloc Device)
	    {
	    HANDLE_ERROR(cudaMalloc(&ptrDevTabData, sizeOctetData));
	    HANDLE_ERROR(cudaMalloc(&ptrDevHisto, sizeOctetHisto));
	    }

	// MM (memset Device)
	    {
	    HANDLE_ERROR(cudaMemset(ptrDevTabData, 0, sizeOctetData));
	    HANDLE_ERROR(cudaMemset(ptrDevHisto, 0, sizeOctetHisto));
	    }

	// MM (copy Host->Device)
	    {
	    HANDLE_ERROR(cudaMemcpy(ptrDevTabData, tabData, sizeOctetData, cudaMemcpyHostToDevice));
	    }

	Device::lastCudaError("Histogramme MM (end allocation)"); // temp debug
	}

    // Grid
	{
	this->dg = dim3(16, 2, 1); // disons, a optimiser selon le gpu
	this->db = dim3(32, 4, 1); // disons, a optimiser selon le gpu

	Device::gridHeuristic(dg, db);
	}
    }

Histogramme::~Histogramme(void)
    {
    //MM (device free)
	{
	HANDLE_ERROR(cudaFree(ptrDevTabData));
	HANDLE_ERROR(cudaFree(ptrDevHisto));

	Device::lastCudaError("Histogramme MM (end deallocation)"); // temp debug
	}

	    delete[] tabData;
	    delete[] ptrHisto;
    }

/*--------------------------------------*\
 |*		Methode			*|
 \*-------------------------------------*/

void Histogramme::run()
    {
    Device::lastCudaError("histogramme (before)"); // temp debug
    histogramme<<<dg,db, sizeOctetHisto>>>(ptrDevTabData, nTabData, ptrDevHisto); // assynchrone
    Device::lastCudaError("histogramme (after)"); // temp debug

    Device::synchronize(); // Temp, only for printf in  GPU

    // MM (Device -> Host)
	{
	HANDLE_ERROR(cudaMemcpy(ptrHisto, ptrDevHisto, sizeOctetHisto, cudaMemcpyDeviceToHost)); // barriere synchronisation implicite
	}

	for(int i = 0; i< N256; i++)
	    {
	    cout << ptrHisto[i];
	    }
	cout << endl;
    }

/*--------------------------------------*\
 |*		Private			*|
 \*-------------------------------------*/

/*----------------------------------------------------------------------*\
 |*			End	 					*|
 \*---------------------------------------------------------------------*/
