#include <iostream>

#include "Device.h"
#include "MonteCarlo.h"

using std::cout;
using std::endl;

/*----------------------------------------------------------------------*\
 |*			Declaration 					*|
 \*---------------------------------------------------------------------*/

/*--------------------------------------*\
 |*		Imported	 	*|
 \*-------------------------------------*/

extern __global__ void monteCarlo(float M, int nbFlechettes);
extern __global__ void setup_kernel_rand(curandState* tabDevGenerator,Device::getDeviceId() )

/*--------------------------------------*\
 |*		Public			*|
 \*-------------------------------------*/

/*--------------------------------------*\
 |*		Private			*|
 \*-------------------------------------*/

/*----------------------------------------------------------------------*\
 |*			Implementation 					*|
 \*---------------------------------------------------------------------*/

/*--------------------------------------*\
 |*		Constructeur			*|
 \*-------------------------------------*/

MonteCarlo::MonteCarlo(float M, int nbFlechettes) :
	M(M), nbFlechettes(nbFlechettes)
    {
    #pragma omp parallel for

    // Grid
	{
	this->dg = dim3(16, 2, 1); // disons, a optimiser selon le gpu
	this->db = dim3(32, 4, 1); // puissance de 2

	Device::gridHeuristic(dg, db);
	}

    // nb de blocks * nb de threads
    this->sizeOctetTabGenerator = dg.x * dg.y * db.z * db.x * db.y * db.z * sizeof(curandState);
    this->sizeOctetN0 = sizeof(int); // octet
    this->sizeSM = db.x * db.y * db.z * sizeof(int);

    this->nbDevice = Device::getDeviceCount();
    this->tabMontecarlo = new float[nbDevice];
    this->ptrDevTabMontecarlo = new float*[nbDevice];
    this->tabDevGeneratorGM = new cuandstate();


    for (int i = 0; i < this->NB_DEVICE; i ++)

    // MM
	{
	// MM (malloc Device)
	    {
	    // TODO: handle cudamemset
	    HANDLE_ERROR(cudaMalloc(&ptrDevTabMontecarlo[i], sizeOctetN0));
	    HANDLE_ERROR(cudaMalloc(&ptrTabDevGeneratorGM[i], sizeOctetTabGenerator));}

	// MM (memset Device)
	    {
	    // TODO: handle cudamalloc
	    HANDLE_ERROR(
		    cudaMemset(ptrDevTabMontecarlo[i], 0, sizeOctetN0));
	    HANDLE_ERROR(cudaMemset(ptrTabDevGeneratorGM[i], 0, sizeOctetN0));}

	    // MM (copy Host->Device)
	    {
	    // rien
	    }

	    Device::lastCudaError("MonteCarlo MM (end allocation)"); // temp debug
	}
    setup_kernel_rand(tabDevGenerator[i], CURAND_RNG_PSEUDO_MTGP32);

    }

MonteCarlo::~MonteCarlo(void)
{
    #pragma omp parallel for

    //MM (device free)
    {
    for(int i = 0; i< nbDevice; i++){
	HANDLE_ERROR(cudaSetDevice(i));
	HANDLE_ERROR(cudaFree(ptrDevTabMontecarlo));
	HANDLE_ERROR(cudaFree(tabDevGeneratorGM));

    }
    delete[] ptrDevTabMontecarlo;
    delete[] tabDevGeneratorGM;
    delete[] tabMontecarlo;

    Device::lastCudaError("MonteCarlo MM (end deallocation)"); // temp debug
}

/*--------------------------------------*\
 |*		Methode			*|
 \*-------------------------------------*/

public float getPi()
{
return this->pi;
}

//TODO omp
// #pragma omp parallel for reduction (+:ntotalUnderCurve)

float MonteCarlo::run()
{
    int ntotalUnderCurve = 0;
    for (int i = 0; i < nbDevice; i++)
	{
	HANDLE_ERROR(cudaSetDevice(i));
	Device::lastCudaError("monteCarlo (before)"); // temp debug

	monteCarlo<<<dg,db, sizeSM>>>(tabDevGeneratorGM[i], ptrTabDevMontecarlo[i], (nbFlechettes/(float)nbDevice));// assynchrone
	Device::lastCudaError("monteCarlo (after)"); // temp debug

	Device::synchronize(); // Temp, only for printf in  GPU

	// MM (Device -> Host)
	{
	    HANDLE_ERROR(cudaMemcpy(&tabMontecarlo[i], ptrDevTabMontecarlo[i], sizeOctetN0, cudaMemcpyDeviceToHost)); // barriere synchronisation implicite
	    //HANDLE_ERROR(cudaMemcpy(&n0, ptrDevN0, sizeOctetN0, cudaMemcpyDeviceToHost)); // barriere synchronisation implicite
	}
	//pi = (N0 / nbFlechettes) * M; // TODO Ã  verifier
	ntotalUnderCurve += tabMontecarlo[i];

	}
    return (ntotalUnderCurve / (double)nbFlechettes) * M;

}

/*--------------------------------------*\
 |*		Private			*|
 \*-------------------------------------*/

/*----------------------------------------------------------------------*\
 |*			End	 					*|
 \*---------------------------------------------------------------------*/
